{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN model:\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "#Convolutional layer:\n",
    "model.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu')) # = feature-detector(kernel) characteristics\n",
    "#Max pooling layer:\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "#Convolutional layer 2:\n",
    "model.add(Convolution2D(32, 3, 3, activation = 'relu')) #border_mode = 'same' #input_shape = (64, 64, 3): we do not add this parameter in this second convolutionallayer since the input for this layer is just the output of the maxpooling of layer 1; thus, all the input data have the same shape by default and do not require further shape defining. \n",
    "#Max pooling layer 2:\n",
    "model.add(MaxPooling2D((2, 2))) #first, we didn't have this \"Convolutional layer 2\", but since he accuracy was low, we figured to add this second Convolutional layer to improve the model's finla performance. But generally when dealing with colored images (also in CIFAR10 dataset) we add this seccond convolutional layer.\n",
    "             \n",
    "#generally, the more (convolutional or ANN) layers we add, the better performance we will have, but also the more run-time we will face. Also, adding to the \"input_shape = (64, 64, 3), (more than 64, like: 128 or 256)+ will again enhance the performance and accuracy.\n",
    "          \n",
    "          \n",
    "#Flattening Layer:\n",
    "model.add(Flatten())\n",
    "          \n",
    "\n",
    "#ANN (= Fully c(onnected layer):\n",
    "model.add(Dense(units = 128, activation = 'relu')) #number of nodes in the hidden layer\n",
    "model.add(Dense(units = 1, activation = 'sigmoid')) #the last layer\n",
    "\n",
    "\n",
    "#Compiling the model:\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      " 208/8000 [..............................] - ETA: 51:20 - loss: 0.6916 - accuracy: 0.5239"
     ]
    }
   ],
   "source": [
    "#Image Augmentation:\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                target_size=(64, 64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary') #target_size=(64, 64): since in the CNN model in the above cell we mentioned \"64 for input_shape\" #batch_size=32: seems okay\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "                    training_set,\n",
    "                    steps_per_epoch=8000,\n",
    "                    epochs=25,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=800) #steps_per_epoch=8000: = the size of the training_set which is 4000 cat images + 4000 dog images = 8000  #validation_steps=2000: = the size of the test_set which is 1000 cat images + 1000 dog images = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
